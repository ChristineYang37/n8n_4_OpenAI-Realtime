(async function(){
  console.log("âœ… realtime.js å·²åŠ è½½");

  //â”€â”€ æ³¨å…¥å¹¶æ‰“å°å…¨å±€å˜é‡ â”€â”€
  const SECRET = window.OPENAI_SECRET;
  const MODEL  = window.OPENAI_MODEL;
  console.log("ğŸ”‘ Injected secret/model:", SECRET, MODEL);

  const chatEl  = document.getElementById("chat");
  const audioEl = document.getElementById("agent-audio");

  function appendBubble(parent, text, clazz, done) {
    if (!text) return;
    const div = document.createElement('div');
    div.className = `bubble ${clazz}` + (done ? ' done' : '');
    div.textContent = text;
    parent.appendChild(div);
    parent.scrollTop = parent.scrollHeight;
  }

  try {
    //â”€â”€ å»ºç«‹ PeerConnection â”€â”€
    const pc = new RTCPeerConnection();
    console.log("ğŸ§Š RTCPeerConnection created");

    pc.onicecandidate = e => console.log("ğŸ§Š ICE candidate:", e.candidate);
    pc.oniceconnectionstatechange = () =>
      console.log("ğŸŒ ICE state:", pc.iceConnectionState);
    pc.onconnectionstatechange = () =>
      console.log("ğŸ”— Connection state:", pc.connectionState);

    //â”€â”€ DataChannel â”€â”€
    const dc = pc.createDataChannel("oai-events");
    dc.onopen = () => {
      console.log("ğŸ“¡ Data channel open (readyState=", dc.readyState, ")");
      // â€” æµ‹è¯•å›ç¯æ¶ˆæ¯ï¼Œç¡®ä¿é€šé“å¯ç”¨ â€”
      dc.send(JSON.stringify({ test: "hello from client" }));
    };
    dc.onmessage = e => {
      console.log("âŒ¨ï¸ Received data-channel message:", e.data);
      let msg;
      try { msg = JSON.parse(e.data); }
      catch(err){ console.warn("âš ï¸ Invalid JSON:", e.data); return; }

      if (msg.test) {
        console.log("ğŸ” Loopback test received:", msg.test);
        return;
      }
      if (msg.conversation?.item?.input_audio_transcription) {
        const d = msg.conversation.item.input_audio_transcription;
        appendBubble(chatEl, d.delta || d.completed, 'user', !!d.completed);
      }
      if (msg.response?.audio_transcript) {
        const r = msg.response.audio_transcript;
        appendBubble(chatEl, r.delta || r.done, 'agent', !!r.done);
      }
    };

    //â”€â”€ éº¦å…‹é£é‡‡é›† & å›æ”¾è°ƒè¯• â”€â”€
    const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    console.log("ğŸ¤ Mic tracks:", micStream.getAudioTracks());
    // å¯é€‰ï¼šåœ¨é¡µé¢ä¸Šå›æ”¾éŸ³é¢‘ï¼Œç¡®è®¤ç¡®å®é‡‡é›†åˆ°å£°éŸ³
    const debugAudio = new Audio();
    debugAudio.srcObject = micStream;
    debugAudio.autoplay = true;
    debugAudio.volume = 0.2;
    document.body.appendChild(debugAudio);

    micStream.getTracks().forEach(track => pc.addTrack(track, micStream));

    //â”€â”€ SDP æ¡æ‰‹ â”€â”€
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    console.log("ğŸ“¨ Offer created (SDP length = ", offer.sdp.length, ")");

    const res = await fetch(
      `https://api.openai.com/v1/realtime?model=${MODEL}`,
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${SECRET}`,
          "Content-Type":  "application/sdp"
        },
        body: offer.sdp,
      }
    );
    console.log("ğŸ“¡ Realtime API response status:", res.status);
    if (!res.ok) throw new Error(`Realtime API returned ${res.status}`);

    const answer = await res.text();
    console.log("ğŸ“© Received answer SDP (length=", answer.length, ")");
    await pc.setRemoteDescription({ type: "answer", sdp: answer });
    console.log("âœ… SDP negotiation complete");

  } catch (err) {
    console.error("âŒ WebRTC error", err);
    const errEl = document.createElement('pre');
    errEl.textContent = "ERROR: " + err;
    chatEl.appendChild(errEl);
  }
})();
