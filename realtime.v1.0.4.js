(async function(){
  console.log("âœ… realtime.js å·²åŠ è½½");

  //â”€â”€ æ³¨å…¥å¹¶æ‰“å°å…¨å±€å˜é‡ â”€â”€
  const SECRET = window.OPENAI_SECRET;
  const MODEL  = window.OPENAI_MODEL;
  console.log("ğŸ”‘ Injected secret/model:", SECRET, MODEL);

  const chatEl  = document.getElementById("chat");
  const audioEl = document.getElementById("agent-audio");

  function appendBubble(parent, text, clazz, done) {
    if (!text) return;
    const div = document.createElement('div');
    div.className = `bubble ${clazz}` + (done ? ' done' : '');
    div.textContent = text;
    parent.appendChild(div);
    parent.scrollTop = parent.scrollHeight;
  }

  try {
    //â”€â”€ å»ºç«‹ PeerConnection â”€â”€
    const pc = new RTCPeerConnection();
    console.log("ğŸ§Š RTCPeerConnection created");

    pc.onicecandidate = e => console.log("ğŸ§Š ICE candidate:", e.candidate);
    pc.oniceconnectionstatechange = () =>
      console.log("ğŸŒ ICE state:", pc.iceConnectionState);
    pc.onconnectionstatechange = () =>
      console.log("ğŸ”— Connection state:", pc.connectionState);

    //â”€â”€ DataChannel â”€â”€
    const dc = pc.createDataChannel("oai-events");
    dc.onopen = () => {
      console.log("ğŸ“¡ Data channel open (readyState=", dc.readyState, ")");
    };
dc.onmessage = e => {
  const raw = e.data;
  console.log("âŒ¨ï¸ Received data-channel message:", raw);
  let msg;
  try {
    msg = JSON.parse(raw);
  } catch {
    console.warn("âš ï¸ é JSON æ¶ˆæ¯ï¼Œä¸å¤„ç†:", raw);
    return;
  }

  // ç”¨æˆ·è¯­éŸ³è½¬æ–‡æœ¬äº‹ä»¶
  if (msg.type === "conversation.item.input_audio_transcription.delta") {
    appendBubble(chatEl, msg.delta, 'user', false);
  }
  else if (msg.type === "conversation.item.input_audio_transcription.completed") {
    appendBubble(chatEl, msg.transcript, 'user', true);
  }

  // Agent æ–‡æœ¬æµäº‹ä»¶
  else if (msg.type === "response.audio_transcript.delta" ||
           msg.type === "response.content_part.delta") {
    // æœ‰çš„äº‹ä»¶ field ç”¨ `delta`
    appendBubble(chatEl, msg.delta, 'agent', false);
  }
  else if (msg.type === "response.audio_transcript.done" ||
           msg.type === "response.content_part.done" ||
           msg.type === "response.output_item.done") {
    // å®Œæ•´å›ç­” text/ audio
    const text = msg.transcript ?? msg.part?.transcript ?? "";
    appendBubble(chatEl, text, 'agent', true);
  }
};

    //â”€â”€ éº¦å…‹é£é‡‡é›† & å›æ”¾è°ƒè¯• â”€â”€
    const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    console.log("ğŸ¤ Mic tracks:", micStream.getAudioTracks());
    // å¯é€‰ï¼šåœ¨é¡µé¢ä¸Šå›æ”¾éŸ³é¢‘ï¼Œç¡®è®¤ç¡®å®é‡‡é›†åˆ°å£°éŸ³
    const debugAudio = new Audio();
    debugAudio.srcObject = micStream;
    debugAudio.autoplay = true;
    debugAudio.volume = 0.2;
    document.body.appendChild(debugAudio);

    micStream.getTracks().forEach(track => pc.addTrack(track, micStream));

    //â”€â”€ SDP æ¡æ‰‹ â”€â”€
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    console.log("ğŸ“¨ Offer created (SDP length = ", offer.sdp.length, ")");

    const res = await fetch(
      `https://api.openai.com/v1/realtime?model=${MODEL}`,
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${SECRET}`,
          "Content-Type":  "application/sdp"
        },
        body: offer.sdp,
      }
    );
    console.log("ğŸ“¡ Realtime API response status:", res.status);
    if (!res.ok) throw new Error(`Realtime API returned ${res.status}`);

    const answer = await res.text();
    console.log("ğŸ“© Received answer SDP (length=", answer.length, ")");
    await pc.setRemoteDescription({ type: "answer", sdp: answer });
    console.log("âœ… SDP negotiation complete");

  } catch (err) {
    console.error("âŒ WebRTC error", err);
    const errEl = document.createElement('pre');
    errEl.textContent = "ERROR: " + err;
    chatEl.appendChild(errEl);
  }
})();